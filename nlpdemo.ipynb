{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7074311,"sourceType":"datasetVersion","datasetId":4074484},{"sourceId":7074508,"sourceType":"datasetVersion","datasetId":4074615},{"sourceId":7074578,"sourceType":"datasetVersion","datasetId":4074665},{"sourceId":7083758,"sourceType":"datasetVersion","datasetId":4081152}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gradio","metadata":{"execution":{"iopub.status.busy":"2023-12-01T07:59:09.247261Z","iopub.execute_input":"2023-12-01T07:59:09.247812Z","iopub.status.idle":"2023-12-01T07:59:48.783318Z","shell.execute_reply.started":"2023-12-01T07:59:09.247775Z","shell.execute_reply":"2023-12-01T07:59:48.781699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\nimport nltk\nimport pandas as pd\nfrom nltk.util import ngrams\nimport pickle\nimport torch\nfrom torch.autograd import Variable\nimport sys\n!pip3 install skipthoughts\nfrom skipthoughts import BiSkip\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import DataLoader, TensorDataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-01T09:05:17.509271Z","iopub.execute_input":"2023-12-01T09:05:17.510415Z","iopub.status.idle":"2023-12-01T09:05:32.574820Z","shell.execute_reply.started":"2023-12-01T09:05:17.510353Z","shell.execute_reply":"2023-12-01T09:05:32.572924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install vaderSentiment\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:05:32.577999Z","iopub.execute_input":"2023-12-01T09:05:32.578527Z","iopub.status.idle":"2023-12-01T09:05:47.463012Z","shell.execute_reply.started":"2023-12-01T09:05:32.578478Z","shell.execute_reply":"2023-12-01T09:05:47.461789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_dict():\n    f = open(\"../input/dictionary1/dictionary.txt\", \"r\")\n    data = f.read()\n    data_lst = data.replace('\\n', ' ').split(\" \")\n    vocab = list(set(data_lst))\n\n    w2i = {}\n    for i in range(len(vocab)):\n        w2i[vocab[i]] = i+1\n    return vocab, w2i","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:05:47.465167Z","iopub.execute_input":"2023-12-01T09:05:47.465585Z","iopub.status.idle":"2023-12-01T09:05:47.474760Z","shell.execute_reply.started":"2023-12-01T09:05:47.465547Z","shell.execute_reply":"2023-12-01T09:05:47.473287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab, w2i = generate_dict()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:05:47.478430Z","iopub.execute_input":"2023-12-01T09:05:47.478855Z","iopub.status.idle":"2023-12-01T09:05:48.807971Z","shell.execute_reply.started":"2023-12-01T09:05:47.478823Z","shell.execute_reply":"2023-12-01T09:05:48.806588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_st = 'skipthoughts'\nbiskip = BiSkip(dir_st, vocab)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:05:48.809537Z","iopub.execute_input":"2023-12-01T09:05:48.809923Z","iopub.status.idle":"2023-12-01T09:06:26.014276Z","shell.execute_reply.started":"2023-12-01T09:05:48.809890Z","shell.execute_reply":"2023-12-01T09:06:26.013104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def external_features(headline, body):\n    vec = []\n\n    # Character n-grams\n    for n in range(2, 17):\n        n_grams_1 = list(ngrams(headline.lower(), n,pad_right=True, right_pad_symbol='</s>'))\n        n_grams_2 = list(ngrams(body.lower(), n,pad_right=True, right_pad_symbol='</s>'))\n        intersection = len(set(n_grams_1).intersection(n_grams_2))\n        vec.append(intersection)\n        temp_c1 = len(set(n_grams_1).intersection(ngrams(body.lower()[:255], n,pad_right=True, right_pad_symbol='</s>')))\n        temp_c2 = len(set(n_grams_1).intersection(ngrams(body.lower()[:100], n,pad_right=True, right_pad_symbol='</s>')))\n        vec.append(temp_c1)\n        vec.append(temp_c2)\n\n    # Word n-grams\n    for n in range(2, 7):\n        n_grams_1 = list(ngrams(headline.lower().split(), n,pad_right=True, right_pad_symbol='</s>'))\n        n_grams_2 = list(ngrams(body.lower().split(), n,pad_right=True, right_pad_symbol='</s>'))\n        intersection = len(set(n_grams_1).intersection(n_grams_2))\n        vec.append(intersection)\n        temp_c = len(set(n_grams_1).intersection(ngrams(body.lower()[:255].split(), n, pad_right=True, right_pad_symbol='</s>')))\n        vec.append(temp_c)\n\n    # Number of common words between headline and body with respect to total words\n    words_set1 = set(headline.split())\n    words_set2 = set(body.split())\n    common_words = len(words_set1.intersection(words_set2)) / max(len(words_set1), len(words_set2))\n    vec.append(common_words)\n\n    sid_obj = SentimentIntensityAnalyzer()\n    d1 = sid_obj.polarity_scores(headline)\n    d2 = sid_obj.polarity_scores(body)\n\n    # Calculate sentiment differences and add them to the feature vector\n    sentiment_diffs = [abs(d1[key] - d2[key]) for key in ['neg', 'neu', 'pos', 'compound']]\n    vec.extend(sentiment_diffs)\n\n    \n\n    vec = np.array(vec)\n    return vec","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:06:26.016096Z","iopub.execute_input":"2023-12-01T09:06:26.016473Z","iopub.status.idle":"2023-12-01T09:06:26.080875Z","shell.execute_reply.started":"2023-12-01T09:06:26.016428Z","shell.execute_reply":"2023-12-01T09:06:26.079294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt',download_dir='/usr/local/share/nltk_data')\nnltk.download('wordnet',download_dir='/usr/local/share/nltk_data')\nnltk.download('omw-1.4')\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nimport re\nfrom sklearn import feature_extraction\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:06:26.082485Z","iopub.execute_input":"2023-12-01T09:06:26.082834Z","iopub.status.idle":"2023-12-01T09:06:26.316256Z","shell.execute_reply.started":"2023-12-01T09:06:26.082806Z","shell.execute_reply":"2023-12-01T09:06:26.315036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip ../../usr/local/share/nltk_data/corpora/wordnet.zip -d ../../usr/local/share/nltk_data/corpora/\n!ls -r ../../usr/local/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:06:26.318562Z","iopub.execute_input":"2023-12-01T09:06:26.319556Z","iopub.status.idle":"2023-12-01T09:07:49.747534Z","shell.execute_reply.started":"2023-12-01T09:06:26.319508Z","shell.execute_reply":"2023-12-01T09:07:49.745731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n_wnl = nltk.WordNetLemmatizer()\ndef normalize_word(word):\n    return _wnl.lemmatize(word).lower()\n\ndef get_tokenized_lemmas(s):\n    list=nltk.word_tokenize(s)\n    tokenized_list=[]\n    for token in list:\n        tokenized_list.append(normalize_word(token))\n    return tokenized_list\n\ndef clean(s):\n    # Cleans a string: Lowercasing, trimming, removing non-alphanumeric\n    return \" \".join(re.findall(r'\\w+', s, flags=re.UNICODE)).lower()\n\ndef remove_stopwords(l):\n    # Removes stopwords from a list of tokens\n    list=[]\n    for word in l:\n        if word not in feature_extraction.text.ENGLISH_STOP_WORDS:\n            list.append(word)\n    return list\n\ndef preprocess(headlines,bodies):\n    n_headlines, n_bodies =[],[]\n    for i, (headline, body) in tqdm(enumerate(zip(headlines, bodies))):\n        clean_headline = get_tokenized_lemmas(clean(headline))\n        clean_body = get_tokenized_lemmas(clean(body))\n        clean_headline = remove_stopwords(clean_headline)\n        clean_body = remove_stopwords(clean_body)\n        n_headlines.append(clean_headline)\n        n_bodies.append(clean_body)\n    n_headlines_df=pd.DataFrame({'Headline':n_headlines})\n    n_bodies_df=pd.DataFrame({'Body':n_bodies})\n    return n_headlines_df['Headline'].apply(lambda x:' '.join(x)), n_bodies_df['Body'].apply(lambda x:' '.join(x))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:07:49.750705Z","iopub.execute_input":"2023-12-01T09:07:49.751303Z","iopub.status.idle":"2023-12-01T09:07:49.769710Z","shell.execute_reply.started":"2023-12-01T09:07:49.751212Z","shell.execute_reply":"2023-12-01T09:07:49.767959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following commented cells dump the vectorizer to a pkl file, do that we could reuse them","metadata":{}},{"cell_type":"code","source":"# df = pd.read_csv('../input/dataset2/train_Set.csv')\n# stop_words_l=stopwords.words('english')\n\n# df['Headline'], df['Body'] = preprocess(df['Headline'],df['Body'])","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:07:49.775350Z","iopub.execute_input":"2023-12-01T09:07:49.776080Z","iopub.status.idle":"2023-12-01T09:07:49.787769Z","shell.execute_reply.started":"2023-12-01T09:07:49.776037Z","shell.execute_reply":"2023-12-01T09:07:49.786343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# headline_vectorizer = TfidfVectorizer(stop_words=stop_words_l,max_features=5000, ngram_range=(1, 1))\n# headline_vectorizer.fit(df['Headline'])\n# vocab_sz_headline = len(headline_vectorizer.vocabulary_)\n# with open('h_vectorizer.pkl', 'wb') as file:\n#     pickle.dump(headline_vectorizer, file)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:07:49.790036Z","iopub.execute_input":"2023-12-01T09:07:49.790409Z","iopub.status.idle":"2023-12-01T09:07:49.805029Z","shell.execute_reply.started":"2023-12-01T09:07:49.790378Z","shell.execute_reply":"2023-12-01T09:07:49.803753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# body_vectorizer = TfidfVectorizer(stop_words=stop_words_l,max_features=10000-vocab_sz_headline)\n# body_vectorizer.fit(df['Body'])\n# with open('b_vectorizer.pkl', 'wb') as file:\n#     pickle.dump(body_vectorizer, file)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:07:49.807222Z","iopub.execute_input":"2023-12-01T09:07:49.807727Z","iopub.status.idle":"2023-12-01T09:07:49.818891Z","shell.execute_reply.started":"2023-12-01T09:07:49.807684Z","shell.execute_reply":"2023-12-01T09:07:49.817574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The required vectorizers are loaded from the respective pickle files","metadata":{}},{"cell_type":"code","source":"with open('../input/vectorizers/h_vectorizer.pkl', 'rb') as file:\n    headline_vectorizer = pickle.load(file)\nwith open('../input/vectorizers/b_vectorizer.pkl', 'rb') as file:\n    body_vectorizer = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:07:49.821192Z","iopub.execute_input":"2023-12-01T09:07:49.821653Z","iopub.status.idle":"2023-12-01T09:07:49.918516Z","shell.execute_reply.started":"2023-12-01T09:07:49.821617Z","shell.execute_reply":"2023-12-01T09:07:49.916970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def statistical_features(headline, body):\n    headlines,bodies = preprocess([headline],[body])\n    h = headline_vectorizer.transform(headlines)\n\n    b = body_vectorizer.transform(bodies)\n    \n    statistical_features = np.concatenate((np.array(h.toarray()),np.array(b.toarray())),axis = 1)\n    return statistical_features","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:07:49.920814Z","iopub.execute_input":"2023-12-01T09:07:49.921824Z","iopub.status.idle":"2023-12-01T09:07:49.928939Z","shell.execute_reply.started":"2023-12-01T09:07:49.921781Z","shell.execute_reply":"2023-12-01T09:07:49.927820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def neural_features(headline, body):\n\n    heads, bodies = [headline, headline], [body, body]\n#     print(headline)\n    MAX_HEADLINE_COUNT = len(headline.split())\n    MAX_BODY_COUNT = len(body.split())\n    \n    head_ids = np.zeros((len(heads), MAX_HEADLINE_COUNT + 1), dtype=np.float32)\n    bdy_ids = np.zeros((len(bodies), MAX_BODY_COUNT + 1), dtype=np.float32)\n    \n    head_encodings = np.zeros((len(heads), 2400), dtype=np.float32)\n    bdy_encodings = np.zeros((len(bodies), 2400), dtype=np.float32)\n    BATCH_SZ = 200\n    \n    for i in range(len(heads)):\n        hl = heads[i].split()\n        body = bodies[i].split()\n\n        for j, word in enumerate(hl):\n            try:\n                head_ids[i][j] = w2i[word]\n            except KeyError:\n                pass\n        for j, word in enumerate(body):\n            try:\n                bdy_ids[i][j] = w2i[word]\n            except KeyError:\n                pass\n\n#     rem = len(heads) % BATCH_SZ\n    \n#     if rem != 0:\n#         print(rem)\n#     print()\n    h = torch.LongTensor(head_ids[0:2])\n    b = torch.LongTensor(bdy_ids[0:2])\n#     print(h.shape)\n    h_tmp = biskip(h).detach().numpy()\n    b_tmp = biskip(b).detach().numpy()\n\n    head_encodings[0:2] = h_tmp\n    bdy_encodings[0:2] = b_tmp\n\n    \n    feat1 = np.zeros((len(heads), 2400), dtype=np.float32)\n    feat2 = np.zeros((len(heads), 2400), dtype=np.float32)\n    \n    for j, (h_vector, b_vector) in enumerate(zip(head_encodings, bdy_encodings)):\n        feat1[j] = np.multiply(h_vector, b_vector)\n        feat2[j] = np.absolute(h_vector - b_vector)\n\n    \n    features = np.concatenate((feat1, feat2), axis=1)\n    return features[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:07:49.930582Z","iopub.execute_input":"2023-12-01T09:07:49.931852Z","iopub.status.idle":"2023-12-01T09:07:49.951102Z","shell.execute_reply.started":"2023-12-01T09:07:49.931810Z","shell.execute_reply":"2023-12-01T09:07:49.949465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, inp_dim_nf=4800, inp_dim_ef=60, inp_dim_sf=10000, out_dim=4):\n        super(Model, self).__init__()\n        out_dim_nf = 100\n        out_dim_ef = 50\n        out_dim_sf = 50\n        \n        # Neural network for input Neural Features\n        self.model_nf = nn.Sequential(\n            nn.Linear(inp_dim_nf, 500),\n            nn.Sigmoid(),\n            nn.Dropout(0.2),\n            nn.Linear(500, out_dim_nf),\n            nn.Sigmoid()\n        )\n\n        # Neural network for input External Features\n        self.model_ef = nn.Sequential(\n            nn.Linear(inp_dim_ef, out_dim_ef),\n            nn.ReLU()\n        )\n        \n        # Neural network for input Statistical Features\n        self.model_sf = nn.Sequential(\n            nn.Linear(inp_dim_sf, 500),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.Linear(500, out_dim_sf),\n            nn.ReLU()\n        )\n\n        # Feature Combined model\n        self.fc = nn.Sequential(\n            nn.BatchNorm1d(out_dim_nf + out_dim_ef + out_dim_sf),\n            nn.Linear(out_dim_nf + out_dim_ef + out_dim_sf, out_dim),\n            nn.Softmax(dim=1)\n        )\n\n    def forward(self, x_nf, x_ef, x_sf):\n        h_nf = self.model_nf(x_nf)\n        h_ef = self.model_ef(x_ef)\n        h_sf = self.model_sf(x_sf)\n        \n        l2_reg_nf = torch.tensor(0.0)\n        for name, param in self.model_nf.named_parameters():\n            if 'weight' in name:\n                l2_reg_nf += torch.norm(param, p=2)\n        \n        l2_reg_sf = torch.tensor(0.0)\n        for name, param in self.model_sf.named_parameters():\n            if 'weight' in name:\n                l2_reg_sf += torch.norm(param, p=2)\n\n        # Concatenate the outputs\n        h = torch.cat((h_nf, h_ef, h_sf), dim=1)\n        # Final prediction\n        o = self.fc(h)\n\n        return o, l2_reg_nf, l2_reg_sf","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:07:49.952851Z","iopub.execute_input":"2023-12-01T09:07:49.953261Z","iopub.status.idle":"2023-12-01T09:07:49.974181Z","shell.execute_reply.started":"2023-12-01T09:07:49.953227Z","shell.execute_reply":"2023-12-01T09:07:49.972590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:07:49.976553Z","iopub.execute_input":"2023-12-01T09:07:49.977107Z","iopub.status.idle":"2023-12-01T09:07:50.080586Z","shell.execute_reply.started":"2023-12-01T09:07:49.977068Z","shell.execute_reply":"2023-12-01T09:07:50.079376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"../input/fncmodel/fncmodel.pth\", map_location=torch.device('cpu')))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:07:50.082737Z","iopub.execute_input":"2023-12-01T09:07:50.083242Z","iopub.status.idle":"2023-12-01T09:07:50.134561Z","shell.execute_reply.started":"2023-12-01T09:07:50.083207Z","shell.execute_reply":"2023-12-01T09:07:50.133644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess1(s):\n    s = s.lower()\n    s = s.replace(\"\\n\",\"\")\n    s = s.replace(\"\\'s\",\" is\")\n    s = s.replace(\"n\\'t\",\" not\")\n    s = s.replace(\"\\'d\",\" would\")\n    return s","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:07:50.135886Z","iopub.execute_input":"2023-12-01T09:07:50.137175Z","iopub.status.idle":"2023-12-01T09:07:50.144635Z","shell.execute_reply.started":"2023-12-01T09:07:50.137140Z","shell.execute_reply":"2023-12-01T09:07:50.143029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classify(head, body):\n    head = preprocess1(head)\n    body = preprocess1(body)\n    X_sf = statistical_features(head,body)[0]\n    X_ef = external_features(head,body)\n    X_nf = neural_features(head, body)\n    X_nf = torch.from_numpy(X_nf).float()\n    X_ef = torch.from_numpy(X_ef).float()\n    X_sf = torch.from_numpy(X_sf).float()\n    with torch.no_grad():\n        model.eval()\n        out, l2_reg_nf, l2_reg_sf = model(X_nf.unsqueeze(0), X_ef.unsqueeze(0), X_sf.unsqueeze(0))\n    class_labels = ['agree', 'disagree', 'discuss', 'unrelated']\n    return class_labels[out.argmax(dim=1)]","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:07:50.146747Z","iopub.execute_input":"2023-12-01T09:07:50.147194Z","iopub.status.idle":"2023-12-01T09:07:50.166014Z","shell.execute_reply.started":"2023-12-01T09:07:50.147163Z","shell.execute_reply":"2023-12-01T09:07:50.164567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head = \"Argentine President Takes On Godson — But Not To Keep Werewolf At Bay\"\nbody = '''\"Nope. Argentina’s President Cristina Fernández de Kirchner has not become godmother of a Jewish baby to stop him from becoming a werewolf – despite what you may have read in multiple news reports.'''","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:07:50.168219Z","iopub.execute_input":"2023-12-01T09:07:50.168793Z","iopub.status.idle":"2023-12-01T09:07:50.179590Z","shell.execute_reply.started":"2023-12-01T09:07:50.168747Z","shell.execute_reply":"2023-12-01T09:07:50.178143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classify(head, body)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:07:50.181473Z","iopub.execute_input":"2023-12-01T09:07:50.181925Z","iopub.status.idle":"2023-12-01T09:07:50.402443Z","shell.execute_reply.started":"2023-12-01T09:07:50.181885Z","shell.execute_reply":"2023-12-01T09:07:50.400888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install googletrans==4.0.0-rc1","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:07:50.404329Z","iopub.execute_input":"2023-12-01T09:07:50.404676Z","iopub.status.idle":"2023-12-01T09:08:06.046418Z","shell.execute_reply.started":"2023-12-01T09:07:50.404647Z","shell.execute_reply":"2023-12-01T09:08:06.045236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from googletrans import Translator,LANGUAGES\ndef translate(txt, src, dest):\n    translator = Translator()\n    translated = translator.translate(txt,src=src,dest=dest)\n    return translated.text","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:08:06.048262Z","iopub.execute_input":"2023-12-01T09:08:06.048803Z","iopub.status.idle":"2023-12-01T09:08:06.057937Z","shell.execute_reply.started":"2023-12-01T09:08:06.048752Z","shell.execute_reply":"2023-12-01T09:08:06.056228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classifier(head, body, lang):\n    # Placeholder function for translation\n    # Implement the actual translation logic here\n    if lang == 'Telugu':\n        head = translate(head, 'te', 'en')\n        body = translate(body, 'te', 'en')\n        return classify(head, body)\n    else:\n        return classify(head, body)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:08:06.060430Z","iopub.execute_input":"2023-12-01T09:08:06.060863Z","iopub.status.idle":"2023-12-01T09:08:06.075200Z","shell.execute_reply.started":"2023-12-01T09:08:06.060829Z","shell.execute_reply":"2023-12-01T09:08:06.073648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head = 'బ్యాంకులకు వరుసగా 3 రోజులు సెలవు.. డిసెంబర్ లిస్ట్ ఇదే.. పనులుంటే ముందే చూస్కోండి!'\nbody = 'బ్యాంక్ కస్టమర్లకు ముఖ్యమైన అలర్ట్. ఈ నెలలో బ్యాంకులకు వరుసగా సెలవులు ఉన్నాయి. పలు పండగల నేపథ్యంలో అన్ని ప్రాంతాల్లో కలుపుకొని 18 రోజులు బ్యాంకులు పనిచేయకపోవచ్చు. ఇవి ప్రాంతాల్ని బట్టి మారతాయని తెలిసిందే. అయితే మీకు బ్యాంకులో ఏదైనా పని ఉంటే.. ఆర్‌బీఐ సెలవుల క్యాలెండర్ చూసుకొని వెళ్తే మంచిదిు'\nprint(translate(head, 'te', 'en'))\nprint()\nprint(translate(body, 'te', 'en'))\nprint()\nprint(classifier(head, body, 'Telugu'))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:27:24.206260Z","iopub.execute_input":"2023-12-01T09:27:24.207877Z","iopub.status.idle":"2023-12-01T09:27:24.819165Z","shell.execute_reply.started":"2023-12-01T09:27:24.207827Z","shell.execute_reply":"2023-12-01T09:27:24.817943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head = 'నేడే ఇండియా, ఆస్ట్రేలియా నాలుగో టీ20.. భారమంతా బౌలర్ల చేతిలోనే.. జట్టులోకి పెళ్లికొడుకు!'\nbody = 'ఇండియా, ఆస్ట్రేలియా టీ20 సమరంలో మరో కీలకమ్యాచ్‌కు రెండు జట్లు సిద్ధమయ్యాయి. ఐదు మ్యాచ్‌ల సిరీస్‌లో టీమిండియా రెండు, ఆస్ట్రేలియా మూడో టీ20లో గెలుపొందాయి. సిరీస్‌లో 2-1 ఆధిక్యంలో ఉన్న టీమిండియా.. నాలుగో టీ20లో గెలిచి సిరీస్ కైవసం చేసుకోవాలని పట్టుదలగా ఉంది. మరోవైపు మూడో టీ20 ప్రదర్శనను రిపీట్ చేసి సిరీస్ సమం చేయాలని కంగారూలు భావిస్తున్నారు. ఈ నేపథ్యంలో ఇవాళ (శుక్రవారం) రాయ్‌పూర్ వేదికగా జరగనున్న నాలుగో టీ20 మ్యాచ్‌ రెండు జట్లకు ప్రతిష్టాత్మకంగా మారిందిు'\nprint(translate(head, 'te', 'en'))\nprint()\nprint(translate(body, 'te', 'en'))\nprint()\nprint(classifier(head, body, 'Telugu'))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:25:57.085667Z","iopub.execute_input":"2023-12-01T09:25:57.086133Z","iopub.status.idle":"2023-12-01T09:25:57.806123Z","shell.execute_reply.started":"2023-12-01T09:25:57.086099Z","shell.execute_reply":"2023-12-01T09:25:57.804692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head = 'No Electricity At Stadium Hosting India Vs Australia T20 Today. Bill Not Paid'\nbody = '''The stadium has an outstanding bill of ₹ 3.16 crore, due to which the electricity connection at the stadium had been cut 5 years ago.'''\n\n# print(translate(head, 'te', 'en'))\n# print()\n# print(translate(body, 'te', 'en'))\n# print()\nprint(classifier(head, body, 'English'))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:09:30.342847Z","iopub.execute_input":"2023-12-01T09:09:30.344146Z","iopub.status.idle":"2023-12-01T09:09:30.506971Z","shell.execute_reply.started":"2023-12-01T09:09:30.344098Z","shell.execute_reply":"2023-12-01T09:09:30.505714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head = 'No Electricity At Stadium Hosting India Vs Australia T20 Today. Bill Not Paid'\nbody = '''The stadium has an outstanding bill of ₹ 3.16 crore, due to which the electricity connection at the stadium had been cut 5 years ago.'''\n\nprint(classifier(head, body, 'English'))\n\nh = (translate(head, 'en', 'te'))\nprint()\nprint(head)\nprint(h)\nprint((translate(h, 'te', 'en')))\nprint()\nb = (translate(body, 'en', 'te'))\nprint(body)\nprint(b)\nprint((translate(b, 'te', 'en')))\nprint()\nprint(classifier(h, b, 'Telugu'))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T09:25:08.175429Z","iopub.execute_input":"2023-12-01T09:25:08.175992Z","iopub.status.idle":"2023-12-01T09:25:09.046682Z","shell.execute_reply.started":"2023-12-01T09:25:08.175956Z","shell.execute_reply":"2023-12-01T09:25:09.045615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}